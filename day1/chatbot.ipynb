{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get repsonse from an LLM\n",
    "\n",
    "\n",
    "To get started, [get an API key](https://g.co/ai/idxGetGeminiKey) and replace the word `API KEY` below with your API key:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build your own Agent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.venv (Python 3.11.9)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/charl/OneDrive/Desktop/Python/aisg-5-day-ai-agent/.venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access the API key from the environment variable\n",
    "api_key = os.getenv(\"SECRET_KEY\")\n",
    "\n",
    "# Configure the model\n",
    "genai.configure(api_key=api_key)\n",
    "model = genai.GenerativeModel(\"gemini-2.0-flash\")\n",
    "\n",
    "# Define the prompt\n",
    "base_prompt = \"\"\"\n",
    "You cycle through Thought, Action, PAUSE, Observation. At the end of the loop you output a final Answer. Your final answer should be highly specific to the observations you have from running\n",
    "the actions.\n",
    "1. Thought: Describe your thoughts about the question you have been asked.\n",
    "2. Action: run one of the actions available to you - then return PAUSE.\n",
    "3. PAUSE\n",
    "4. Observation: will be the result of running those actions.\n",
    "\n",
    "Available actions:\n",
    "- getCurrentWeather: \n",
    "    E.g. getCurrentWeather: Salt Lake City\n",
    "    Returns the current weather of the location specified.\n",
    "- getLocation:\n",
    "    E.g. getLocation: null\n",
    "    Returns user's location details. No arguments needed.\n",
    "\n",
    "Example session:\n",
    "Question: Please give me some ideas for activities to do this afternoon.\n",
    "Thought: I should look up the user's location so I can give location-specific activity ideas.\n",
    "Action: getLocation: null\n",
    "PAUSE\n",
    "\n",
    "You will be called again with something like this:\n",
    "Observation: \"New York City, NY\"\n",
    "\n",
    "Then you loop again:\n",
    "Thought: To get even more specific activity ideas, I should get the current weather at the user's location.\n",
    "Action: getCurrentWeather: New York City\n",
    "PAUSE\n",
    "\n",
    "You'll then output:\n",
    "Answer: <Suggested activities based on sunny weather that are highly specific to New York City and surrounding areas.>\n",
    "\"\"\"\n",
    "\n",
    "# Dummy functions\n",
    "def recallConvo(place=None):\n",
    "    # Debug\n",
    "    return {}\n",
    "\n",
    "def addToRecall(place=None):\n",
    "    # Debug\n",
    "    return {}\n",
    "\n",
    "available_functions = {\n",
    "    \"recallConvo\": recallConvo,\n",
    "    \"addToRecall\": addToRecall\n",
    "}\n",
    "\n",
    "# Regex for parsing actions\n",
    "action_regex = r\"^Action: (\\w+): (.*)$\"\n",
    "\n",
    "# Initialize variables\n",
    "observation = None\n",
    "max_calls = 5\n",
    "\n",
    "# Start the loop\n",
    "for i in range(max_calls):\n",
    "    print(f\"\\n--- Call {i + 1} ---\")\n",
    "    \n",
    "    # Build the dynamic prompt\n",
    "    if observation:\n",
    "        full_prompt = f\"{base_prompt}\\n\\nUser: {query}\\nAssistant: {observation}\\n\\nUser:\"\n",
    "    else:\n",
    "        full_prompt = f\"{base_prompt}\\n\\nUser: {query}\\nAssistant:\"\n",
    "\n",
    "    # Generate response from the model\n",
    "    response = model.generate_content(full_prompt)\n",
    "    response_text = response.parts[0].text.strip()\n",
    "    print(f\"Response:\\n{response_text}\")\n",
    "\n",
    "    # Split response text into lines\n",
    "    response_lines = response_text.split(\"\\n\")\n",
    "    \n",
    "    # Find the action string in the response\n",
    "    found_action_str = next((line for line in response_lines if re.match(action_regex, line)), None)\n",
    "   \n",
    "\n",
    "    if found_action_str:\n",
    "        # Parse the action and arguments\n",
    "        actions = re.match(action_regex, found_action_str)\n",
    "        if actions:\n",
    "            action, action_arg = actions.groups()\n",
    "            if action in available_functions:\n",
    "                # Execute the action\n",
    "                observation = available_functions[action](action_arg)\n",
    "            else:\n",
    "                print(f\"Invalid action: {action}\")\n",
    "                break\n",
    "        else:\n",
    "            print(\"No valid action match.\")\n",
    "            break\n",
    "    else:\n",
    "        print(\"No valid action found in response.\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the second iteration  the model provides repsponse based on the user's location. The code terminates the call to the model  as it has already found the user's location. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
